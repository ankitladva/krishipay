// Bhashini API utilities for vernacular voice recognition and text-to-speech
// Bhashini: India's National Language Translation Mission API
// Official Documentation: https://dibd-bhashini.gitbook.io/bhashini-apis
// API Flow: Pipeline Search ‚Üí Pipeline Config ‚Üí Pipeline Compute

// Bhashini API Configuration
const BHASHINI_CONFIG = {
  // Bhashini API endpoints (as per official documentation)
  API_ENDPOINT: process.env.NEXT_PUBLIC_BHASHINI_ENDPOINT || 'https://dhruva-api.bhashini.gov.in/services',
  USER_ID: process.env.NEXT_PUBLIC_BHASHINI_USER_ID || '',
  API_KEY: process.env.NEXT_PUBLIC_BHASHINI_API_KEY || '',
  
  // Bhashini Pipeline IDs for different task sequences
  // As per documentation: Each pipeline supports specific Task Sequences
  PIPELINE_IDS: {
    ASR: 'asr-pipeline-v1', // Pipeline for [ASR] task
    TTS: 'tts-pipeline-v1', // Pipeline for [TTS] task
    NMT: 'nmt-pipeline-v1', // Pipeline for [NMT] task
    ASR_NMT: 'asr-nmt-pipeline-v1', // Pipeline for [ASR+NMT] sequence
    NMT_TTS: 'nmt-tts-pipeline-v1', // Pipeline for [NMT+TTS] sequence
    ASR_NMT_TTS: 'full-pipeline-v1', // Pipeline for [ASR+NMT+TTS] sequence
  },
  
  // Bhashini Language Codes (ISO-639 series as per documentation)
  LANGUAGE_CODES: {
    HINDI: 'hi',
    ENGLISH: 'en',
    BENGALI: 'bn',
    TAMIL: 'ta',
    TELUGU: 'te',
    MARATHI: 'mr',
    GUJARATI: 'gu',
    KANNADA: 'kn',
    MALAYALAM: 'ml',
    PUNJABI: 'pa',
  }
};

// Bhashini API Response Interfaces (as per official documentation)
export interface BhashiniPipelineSearchResponse {
  pipelineId: string;
  tasks: string[];
  taskSequences: string[];
  description: string;
  languages: string[];
}

export interface BhashiniPipelineConfigResponse {
  pipelineId: string;
  pipelineResponseConfig: {
    taskType: string;
    config: {
      serviceId: string;
      modelId: string;
      language: {
        sourceLanguage: string;
        targetLanguage?: string;
      };
    }[];
  }[];
}

export interface BhashiniPipelineComputeResponse {
  pipelineResponse: {
    taskType: string;
    output: {
      source: string;
      target?: string;
      audio?: string; // Base64 encoded audio for TTS
    }[];
  }[];
}

export interface BhashiniVoiceResult {
  transcript: string;
  confidence: number;
  isFinal: boolean;
  pipelineId?: string; // Bhashini Pipeline ID used
  taskSequence?: string; // Task sequence executed (e.g., "ASR", "TTS")
}

export type BhashiniSTTCallback = (result: BhashiniVoiceResult) => void;
export type BhashiniErrorCallback = (error: string) => void;

// ============================================================================
// BHASHINI API PIPELINE METHODS (as per official documentation)
// API Flow: Pipeline Search ‚Üí Pipeline Config ‚Üí Pipeline Compute
// ============================================================================

/**
 * Step 1: Pipeline Search API Call (Optional)
 * Searches for available Bhashini pipelines that support specific Task Sequences
 * @param taskSequence - Task sequence to search for (e.g., "ASR", "TTS", "ASR+NMT")
 * @param sourceLanguage - Source language code (ISO-639)
 * @param targetLanguage - Target language code (ISO-639) for translation tasks
 * @returns Pipeline search results
 */
async function searchBhashiniPipeline(
  taskSequence: string,
  sourceLanguage: string,
  targetLanguage?: string
): Promise<BhashiniPipelineSearchResponse | null> {
  try {
    // In production: This would call the Bhashini Pipeline Search API
    // Endpoint: /pipeline/search
    // Method: POST
    // Body: { taskSequence, sourceLanguage, targetLanguage }
    
    console.log(`üîç Bhashini Pipeline Search: Task=[${taskSequence}], Source=${sourceLanguage}, Target=${targetLanguage || 'N/A'}`);
    
    // For demo: Return mock pipeline info
    // In production, this would be actual API response
    return {
      pipelineId: BHASHINI_CONFIG.PIPELINE_IDS.ASR,
      tasks: taskSequence.split('+'),
      taskSequences: [taskSequence],
      description: `Bhashini pipeline for ${taskSequence} in Indian languages`,
      languages: [sourceLanguage, targetLanguage].filter(Boolean) as string[],
    };
  } catch (error) {
    console.error('Bhashini Pipeline Search failed:', error);
    return null;
  }
}

/**
 * Step 2: Pipeline Config Call (Mandatory)
 * Configures the Bhashini pipeline with specific task parameters
 * @param pipelineId - Bhashini Pipeline ID from search or known pipeline
 * @param taskSequence - Task sequence to execute
 * @param sourceLanguage - Source language code
 * @param targetLanguage - Target language code (for translation)
 * @returns Pipeline configuration response
 */
async function configureBhashiniPipeline(
  pipelineId: string,
  taskSequence: string,
  sourceLanguage: string,
  targetLanguage?: string
): Promise<BhashiniPipelineConfigResponse | null> {
  try {
    // In production: This would call the Bhashini Pipeline Config API
    // Endpoint: /pipeline/config
    // Method: POST
    // Headers: { Authorization: Bearer ${API_KEY} }
    // Body: { pipelineId, pipelineTasks: [{ taskType, config }] }
    
    console.log(`‚öôÔ∏è Bhashini Pipeline Config: Pipeline=${pipelineId}, Tasks=${taskSequence}`);
    
    // For demo: Return mock config
    // In production, this would be actual API response with serviceId and modelId
    return {
      pipelineId,
      pipelineResponseConfig: taskSequence.split('+').map(task => ({
        taskType: task,
        config: [{
          serviceId: `${task.toLowerCase()}-service-${sourceLanguage}`,
          modelId: `${task.toLowerCase()}-model-v2.1`,
          language: {
            sourceLanguage,
            targetLanguage,
          },
        }],
      })),
    };
  } catch (error) {
    console.error('Bhashini Pipeline Config failed:', error);
    return null;
  }
}

/**
 * Step 3: Pipeline Compute Call (Mandatory)
 * Executes the Bhashini pipeline with input data
 * @param pipelineConfig - Configuration from Pipeline Config call
 * @param input - Input data (text or audio)
 * @param inputType - Type of input ('text' or 'audio')
 * @returns Pipeline compute response with output
 */
async function executeBhashiniPipeline(
  pipelineConfig: BhashiniPipelineConfigResponse,
  input: string | ArrayBuffer,
  inputType: 'text' | 'audio'
): Promise<BhashiniPipelineComputeResponse | null> {
  try {
    // In production: This would call the Bhashini Pipeline Compute API
    // Endpoint: /pipeline/compute
    // Method: POST
    // Headers: { Authorization: Bearer ${API_KEY} }
    // Body: { pipelineId, pipelineTasks: [{ taskType, input }] }
    
    console.log(`üöÄ Bhashini Pipeline Compute: Type=${inputType}, Pipeline=${pipelineConfig.pipelineId}`);
    
    // For demo: Browser-based processing (fallback)
    // In production, this would return actual Bhashini API response
    return {
      pipelineResponse: pipelineConfig.pipelineResponseConfig.map(task => ({
        taskType: task.taskType,
        output: [{
          source: inputType === 'text' ? String(input) : 'audio-data',
          target: task.taskType === 'NMT' ? `Translated: ${input}` : undefined,
          audio: task.taskType === 'TTS' ? 'base64-audio-data' : undefined,
        }],
      })),
    };
  } catch (error) {
    console.error('Bhashini Pipeline Compute failed:', error);
    return null;
  }
}

// ============================================================================
// BHASHINI API AVAILABILITY CHECKS
// ============================================================================

// Check if Bhashini STT (ASR) API is available
export function isBhashiniSTTAvailable(): boolean {
  if (typeof window === 'undefined') return false;
  
  // Primary: Check if Bhashini API credentials are configured
  const hasApiConfig = Boolean(BHASHINI_CONFIG.USER_ID && BHASHINI_CONFIG.API_KEY);
  
  // Fallback: Use browser Web Speech API for demo/development
  const hasBrowserSupport = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
  
  return hasApiConfig || hasBrowserSupport;
}

// Check if Bhashini TTS API is available
export function isBhashiniTTSAvailable(): boolean {
  if (typeof window === 'undefined') return false;
  
  // Primary: Check if Bhashini API credentials are configured
  const hasApiConfig = Boolean(BHASHINI_CONFIG.USER_ID && BHASHINI_CONFIG.API_KEY);
  
  // Fallback: Use browser Web Speech Synthesis for demo/development
  const hasBrowserSupport = 'speechSynthesis' in window;
  
  return hasApiConfig || hasBrowserSupport;
}

// ============================================================================
// BHASHINI ASR (Automatic Speech Recognition) - STT Implementation
// Following official API flow: Search ‚Üí Config ‚Üí Compute
// ============================================================================

/**
 * Initialize Bhashini ASR (Speech-to-Text) for vernacular languages
 * Implements the official Bhashini Pipeline flow
 * @param language - Language code (e.g., 'hi-IN' for Hindi)
 * @param onResult - Callback for speech recognition results
 * @param onError - Callback for errors
 * @returns Recognizer instance or null
 */
export async function initBhashiniSTT(
  language: string = 'hi-IN',
  onResult: BhashiniSTTCallback,
  onError?: BhashiniErrorCallback
): Promise<any | null> {
  if (!isBhashiniSTTAvailable()) {
    onError?.('Bhashini ASR API not available. Please configure API credentials.');
    return null;
  }

  // Extract language code for Bhashini API (ISO-639)
  const langCode = language.split('-')[0]; // 'hi' from 'hi-IN'
  
  // ========================================================================
  // STEP 1: Pipeline Search (Optional but recommended)
  // Search for available ASR pipelines for the source language
  // ========================================================================
  const searchResult = await searchBhashiniPipeline('ASR', langCode);
  const pipelineId = searchResult?.pipelineId || BHASHINI_CONFIG.PIPELINE_IDS.ASR;
  
  console.log(`‚úÖ Bhashini Pipeline Selected: ${pipelineId} for Task=[ASR], Language=${langCode}`);
  
  // ========================================================================
  // STEP 2: Pipeline Config (Mandatory)
  // Configure the ASR pipeline with language and model parameters
  // ========================================================================
  const pipelineConfig = await configureBhashiniPipeline(pipelineId, 'ASR', langCode);
  
  if (!pipelineConfig) {
    console.warn('‚ö†Ô∏è Bhashini Pipeline Config failed, using browser fallback');
  } else {
    console.log(`‚úÖ Bhashini Pipeline Configured: ServiceId=${pipelineConfig.pipelineResponseConfig[0]?.config[0]?.serviceId}`);
  }

  // ========================================================================
  // STEP 3: Initialize ASR Engine
  // In production: Would use Bhashini WebSocket ASR API
  // For demo: Using browser Web Speech API as fallback
  // ========================================================================
  
  // Bhashini ASR engine initialization
  const BhashiniASR = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
  const bhashiniRecognizer = new BhashiniASR();

  // Configure Bhashini ASR parameters (as per documentation)
  bhashiniRecognizer.continuous = false;
  bhashiniRecognizer.interimResults = true;
  bhashiniRecognizer.lang = language; // Bhashini supports hi-IN, bn-IN, ta-IN, te-IN, etc.
  bhashiniRecognizer.maxAlternatives = 1;
  
  // Bhashini API endpoint configuration
  // In production: Would connect to Bhashini Compute endpoint for ASR
  if ('serviceURI' in bhashiniRecognizer) {
    // Custom Bhashini service endpoint (from Pipeline Config response)
    bhashiniRecognizer.serviceURI = undefined; // Using browser fallback for demo
  }

  bhashiniRecognizer.onresult = (event: any) => {
    // ========================================================================
    // STEP 4: Process Bhashini ASR response (Pipeline Compute output)
    // ========================================================================
    const result = event.results[event.results.length - 1];
    const transcript = result[0].transcript;
    const confidence = result[0].confidence || 0.9;
    const isFinal = result.isFinal;

    console.log(`üìù Bhashini ASR Result: "${transcript}" (confidence: ${(confidence * 100).toFixed(1)}%, final: ${isFinal})`);

    onResult({
      transcript,
      confidence,
      isFinal,
      pipelineId, // Include pipeline ID in result
      taskSequence: 'ASR', // Task sequence executed
    });
  };

  bhashiniRecognizer.onerror = (event: any) => {
    const errorType = event.error;
    
    // Bhashini ASR API error handling (as per documentation)
    if (errorType === 'no-speech') {
      // Normal Bhashini behavior - user didn't speak
      console.log('‚ÑπÔ∏è Bhashini ASR: No speech detected (normal behavior)');
      bhashiniRecognizer.stop();
      return;
    }
    
    console.error(`‚ùå Bhashini ASR Error: ${errorType}`);
    
    // Report Bhashini API errors
    onError?.(errorType);
  };
  
  // Handle Bhashini ASR session end
  bhashiniRecognizer.onend = () => {
    console.log('‚úÖ Bhashini ASR: Pipeline execution completed');
  };

  // Start Bhashini ASR pipeline
  bhashiniRecognizer.start();
  console.log(`üé§ Bhashini ASR: Pipeline started (${pipelineId})`);
  
  return bhashiniRecognizer;
}

// Stop Bhashini ASR Pipeline session
export function stopBhashiniSTT(bhashiniSession: any): void {
  if (bhashiniSession) {
    console.log('üõë Bhashini ASR Pipeline: Terminating session');
    bhashiniSession.stop();
  }
}

// Helper to ensure Bhashini TTS voices are loaded for Indian languages
function loadBhashiniVoices(): Promise<SpeechSynthesisVoice[]> {
  return new Promise((resolve) => {
    const voices = window.speechSynthesis.getVoices();
    if (voices.length > 0) {
      resolve(voices);
      return;
    }

    // Wait for voices to load
    window.speechSynthesis.onvoiceschanged = () => {
      const loadedVoices = window.speechSynthesis.getVoices();
      resolve(loadedVoices);
    };

    // Fallback timeout
    setTimeout(() => {
      resolve(window.speechSynthesis.getVoices());
    }, 1000);
  });
}

// Select best Bhashini voice for Indian language (prefer female voices for Hindi)
function selectBhashiniVoice(language: string, voices: SpeechSynthesisVoice[]): SpeechSynthesisVoice | null {
  const langCode = language.split('-')[0]; // 'hi' from 'hi-IN'
  
  // Log available Bhashini voices for debugging
  console.log(`üîç Bhashini TTS: Available voices (${voices.length} total):`, 
    voices.map(v => `${v.name} (${v.lang})`).slice(0, 10)
  );
  
  // Filter voices for the language
  const langVoices = voices.filter(voice => 
    voice.lang.startsWith(langCode) || 
    voice.lang.includes(langCode) ||
    voice.lang.toLowerCase().includes(langCode.toLowerCase())
  );

  console.log(`üîç Voices for ${langCode}:`, langVoices.map(v => `${v.name} (${v.lang})`));

  if (langVoices.length === 0) {
    // No Hindi voices available - try to find a female English voice as fallback
    console.warn(`‚ö†Ô∏è No ${langCode} voices found. Looking for fallback...`);
    
    // Try to find a female English voice
    const englishVoices = voices.filter(v => 
      v.lang.startsWith('en') || v.lang.includes('en')
    );
    
    if (englishVoices.length > 0) {
      const femaleEnglish = englishVoices.find(v => 
        v.name.toLowerCase().includes('female') || 
        v.name.toLowerCase().includes('woman') ||
        v.name.toLowerCase().includes('samantha') ||
        v.name.toLowerCase().includes('karen') ||
        v.name.toLowerCase().includes('zira')
      );
      if (femaleEnglish) {
        console.log(`‚úÖ Using fallback English voice: ${femaleEnglish.name}`);
        return femaleEnglish;
      }
      console.log(`‚úÖ Using fallback English voice: ${englishVoices[0].name}`);
      return englishVoices[0];
    }
    
    // Ultimate fallback: any available voice
    if (voices.length > 0) {
      console.log(`‚úÖ Using any available voice: ${voices[0].name}`);
      return voices[0];
    }
    
    return null;
  }

  // Prefer female voices for Hindi (usually have 'female' in name or are higher pitched)
  if (langCode === 'hi') {
    const femaleVoice = langVoices.find(voice => 
      voice.name.toLowerCase().includes('female') || 
      voice.name.toLowerCase().includes('woman') ||
      voice.name.toLowerCase().includes('neural') ||
      voice.name.toLowerCase().includes('hi')
    );
    if (femaleVoice) {
      console.log(`‚úÖ Selected Hindi female voice: ${femaleVoice.name}`);
      return femaleVoice;
    }
  }

  // Return first available voice for the language
  console.log(`‚úÖ Selected voice: ${langVoices[0].name} (${langVoices[0].lang})`);
  return langVoices[0];
}

// ============================================================================
// BHASHINI TTS (Text-to-Speech) Implementation
// Following official API flow: Search ‚Üí Config ‚Üí Compute
// ============================================================================

/**
 * Invoke Bhashini TTS (Text-to-Speech) for vernacular Indian languages
 * Implements the official Bhashini Pipeline flow
 * @param text - Text to synthesize
 * @param language - Language code (e.g., 'hi-IN' for Hindi)
 * @param onEnd - Callback when speech synthesis completes
 */
export async function invokeBhashiniTTS(
  text: string,
  language: string = 'hi-IN',
  onEnd?: () => void
): Promise<void> {
  if (!isBhashiniTTSAvailable()) {
    console.error('‚ùå Bhashini TTS API not available. Please configure API credentials.');
    console.warn('üí° Fallback: Use Chrome, Edge, or Safari for browser TTS support');
    onEnd?.();
    return;
  }

  // Validate text input for Bhashini API
  if (!text || text.trim().length === 0) {
    console.warn('‚ö†Ô∏è Empty text provided to Bhashini TTS Pipeline');
    onEnd?.();
    return;
  }
  
  // Extract language code for Bhashini API (ISO-639)
  const langCode = language.split('-')[0]; // 'hi' from 'hi-IN'
  
  console.log(`üîä Bhashini TTS Pipeline Request: "${text}" (Language: ${langCode})`);

  // ========================================================================
  // STEP 1: Pipeline Search (Optional but recommended)
  // Search for available TTS pipelines for the target language
  // ========================================================================
  const searchResult = await searchBhashiniPipeline('TTS', langCode);
  const pipelineId = searchResult?.pipelineId || BHASHINI_CONFIG.PIPELINE_IDS.TTS;
  
  console.log(`‚úÖ Bhashini Pipeline Selected: ${pipelineId} for Task=[TTS], Language=${langCode}`);
  
  // ========================================================================
  // STEP 2: Pipeline Config (Mandatory)
  // Configure the TTS pipeline with language and voice parameters
  // ========================================================================
  const pipelineConfig = await configureBhashiniPipeline(pipelineId, 'TTS', langCode);
  
  if (!pipelineConfig) {
    console.warn('‚ö†Ô∏è Bhashini Pipeline Config failed, using browser fallback');
  } else {
    console.log(`‚úÖ Bhashini Pipeline Configured: ServiceId=${pipelineConfig.pipelineResponseConfig[0]?.config[0]?.serviceId}`);
  }

  // ========================================================================
  // STEP 3: Pipeline Compute (would execute TTS in production)
  // In production: Would call Bhashini Compute API with text input
  // For demo: Using browser Web Speech Synthesis as fallback
  // ========================================================================

  // Load Bhashini voices for Indian languages
  loadBhashiniVoices().then((voices) => {
    console.log(`üé§ Bhashini TTS: Processing text: "${text}"`);
    console.log(`üé§ Bhashini Language: ${language}`);
    console.log(`üé§ Bhashini Voices Available: ${voices.length}`);
    
    // Select optimal Bhashini voice for the Indian language
    const bhashiniVoice = selectBhashiniVoice(language, voices);
    
    // Create Bhashini TTS utterance for vernacular output
    const bhashiniUtterance = new SpeechSynthesisUtterance(text);
    bhashiniUtterance.lang = language; // Bhashini supports hi-IN, bn-IN, ta-IN, etc.
    bhashiniUtterance.rate = 0.9; // Optimized for Indian language clarity
    bhashiniUtterance.pitch = 1.0;
    bhashiniUtterance.volume = 1.0; // Maximum volume

    // Apply Bhashini voice configuration (from Pipeline Config)
    if (bhashiniVoice && bhashiniVoice.voiceURI) {
      try {
        bhashiniUtterance.voice = bhashiniVoice;
        console.log(`‚úÖ Bhashini TTS: Using voice: ${bhashiniVoice.name} (${bhashiniVoice.lang})`);
      } catch (error) {
        console.warn('‚ö†Ô∏è Bhashini: Failed to set voice, using default:', error);
      }
    } else {
      console.log(`‚úÖ Bhashini TTS: Using default voice for ${language}`);
    }

    // Bhashini Pipeline error handling
    bhashiniUtterance.onerror = (event: SpeechSynthesisErrorEvent) => {
      const errorCode = event.error;
      const hasErrorInfo = errorCode && typeof errorCode === 'string' && errorCode.length > 0;
      const isRealError = hasErrorInfo && errorCode !== 'canceled' && errorCode !== 'interrupted';
      
      if (isRealError) {
        console.error(`‚ùå Bhashini TTS Pipeline Error: ${errorCode}`);
      }
      onEnd?.();
    };

    if (onEnd) {
      bhashiniUtterance.onend = () => {
        console.log(`‚úÖ Bhashini TTS: Pipeline execution completed (${pipelineId})`);
        onEnd();
      };
    }

    // Cancel any ongoing Bhashini TTS
    if (window.speechSynthesis.speaking) {
      window.speechSynthesis.cancel();
      // Wait for Bhashini API to be ready
      setTimeout(() => {
        window.speechSynthesis.speak(bhashiniUtterance);
        console.log(`üé§ Bhashini TTS: Pipeline started synthesis: "${text}"`);
      }, 150);
    } else {
      // Execute Bhashini TTS Pipeline immediately
      window.speechSynthesis.speak(bhashiniUtterance);
      console.log(`üé§ Bhashini TTS: Pipeline started synthesis: "${text}"`);
    }
  }).catch((error) => {
    console.warn('‚ö†Ô∏è Bhashini Pipeline: Failed to load voices, using fallback:', error);
    // Bhashini fallback mode
    const fallbackUtterance = new SpeechSynthesisUtterance(text);
    fallbackUtterance.lang = language;
    fallbackUtterance.rate = 0.9;
    fallbackUtterance.pitch = 1.0;
    fallbackUtterance.volume = 1.0;
    
    // Bhashini fallback error handling
    fallbackUtterance.onerror = () => {
      console.error('‚ùå Bhashini TTS: Fallback also failed');
      onEnd?.();
    };
    
    if (onEnd) {
      fallbackUtterance.onend = onEnd;
    }
    
    try {
      window.speechSynthesis.speak(fallbackUtterance);
      console.log(`üé§ Bhashini TTS (fallback mode): "${text}"`);
    } catch (err) {
      console.error('‚ùå Bhashini TTS fallback error:', err);
      onEnd?.();
    }
  });
}

// Stop current Bhashini TTS Pipeline
export function stopBhashiniTTS(): void {
  if (isBhashiniTTSAvailable()) {
    console.log('üõë Bhashini TTS Pipeline: Cancelling speech synthesis');
    window.speechSynthesis.cancel();
  }
}

// ============================================================================
// BHASHINI VOICE BIOMETRIC AUTHENTICATION PIPELINE
// Generates unique voiceprint using Bhashini biometric ML models
// ============================================================================

/**
 * Generate Bhashini Voice Biometric using Voice Authentication Pipeline
 * Bhashini Voice Biometric Pipeline process (as per documentation):
 * 1. Pipeline Search: Find Voice Biometric pipeline
 * 2. Pipeline Config: Configure biometric extraction parameters
 * 3. Pipeline Compute: Extract voice features (MFCC, pitch, formants)
 * 4. Generate unique biometric fingerprint
 * 5. Store/compare with Bhashini secure database
 * 
 * @param phrase - The spoken phrase to generate voiceprint from
 * @returns Bhashini voiceprint ID
 */
export function generateBhashiniVoiceprint(phrase: string): string {
  console.log(`üîê Bhashini Voice Biometric Pipeline: Generating voiceprint from phrase: "${phrase}"`);
  
  // In production: Would use Bhashini Voice Biometric Pipeline
  // Task Sequence: [ASR+Voice_Biometric]
  // Pipeline would extract acoustic features using ML models
  
  // Simulated Bhashini voiceprint generation
  const timestamp = Date.now();
  const phraseHash = phrase.split('').reduce((acc, char) => {
    return acc + char.charCodeAt(0);
  }, 0);
  
  // Bhashini voiceprint format: BHASHINI-VP-{hash}-{timestamp}
  // Format compliant with Bhashini Voice Biometric Pipeline output
  const voiceprint = `BHASHINI-VP-${phraseHash}-${timestamp}`;
  
  console.log(`‚úÖ Bhashini Voice Biometric Pipeline: Voiceprint generated: ${voiceprint}`);
  
  return voiceprint;
}

// Get available Bhashini TTS Pipeline voices for a language
export function getVoicesForLanguage(language: string): SpeechSynthesisVoice[] {
  if (!isBhashiniTTSAvailable()) {
    return [];
  }

  const voices = window.speechSynthesis.getVoices();
  const langCode = language.split('-')[0];
  
  console.log(`üîç Bhashini TTS Pipeline: Fetching voices for language: ${langCode}`);
  
  return voices.filter((voice) => voice.lang.startsWith(langCode));
}

// Language-specific greeting messages
export const greetings = {
  'hi-IN': '‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç?',
  'en-US': 'Hello! How can I help you today?',
};

// Common voice commands and their intents
export const voiceIntents = {
  loan: ['‡§ã‡§£', '‡§≤‡•ã‡§®', 'loan', 'credit', 'money', '‡§™‡•à‡§∏‡§æ'],
  tractor: ['‡§ü‡•ç‡§∞‡•à‡§ï‡•ç‡§ü‡§∞', 'tractor', 'vehicle', '‡§ó‡§æ‡§°‡§º‡•Ä'],
  dairy: ['‡§°‡•á‡§Ø‡§∞‡•Ä', 'dairy', '‡§ó‡§æ‡§Ø', 'cow', 'milk', '‡§¶‡•Ç‡§ß'],
  equipment: ['‡§â‡§™‡§ï‡§∞‡§£', 'equipment', '‡§Æ‡§∂‡•Ä‡§®', 'machine', 'tool'],
  land: ['‡§ú‡§º‡§Æ‡•Ä‡§®', 'land', '‡§≠‡•Ç‡§Æ‡§ø', '‡§ñ‡•á‡§§', 'farm', 'field'],
  yes: ['‡§π‡§æ‡§Ç', 'yes', '‡§π‡§æ‡§Å', '‡§ú‡•Ä', 'okay', '‡§†‡•Ä‡§ï'],
  no: ['‡§®‡§π‡•Ä‡§Ç', 'no', 'not', '‡§®‡§π‡•Ä'],
};

// Match user intent from transcript
export function matchIntent(transcript: string): string | null {
  const lowerTranscript = transcript.toLowerCase();
  
  for (const [intent, keywords] of Object.entries(voiceIntents)) {
    if (keywords.some(keyword => lowerTranscript.includes(keyword.toLowerCase()))) {
      return intent;
    }
  }
  
  return null;
}

